"""Context builder for assembling agent prompts."""

import base64
import mimetypes
from pathlib import Path
from typing import Any

from nanobot.agent.memory import MemoryStore
from nanobot.agent.skills import SkillsLoader
from nanobot.utils.helpers import estimate_tokens, truncate_to_token_limit


TOKEN_BUDGET_DEFAULTS = {
    "identity": 500,
    "bootstrap": 1500,
    "memory": 2000,
    "skills": 500,
    "total": 5000,
}

# ä¸» Agent é»˜è®¤èº«ä»½å†…å®¹ï¼ˆä¸å« runtime_suffixï¼‰ï¼Œç”¨äºŽå¯åŠ¨æ—¶åˆå§‹åŒ– DB åŠå†…ç½®å›žé€€
DEFAULT_IDENTITY_CONTENT = """# nanobot ðŸˆ

You are nanobot, a helpful AI assistant.

## Behavior Guidelines

- Be helpful, accurate, and concise
- Use tools when needed, explain what you're doing
- When user says "è®°ä½/remember", call the remember tool to persist the information
- For normal conversation, respond with text directly. Only use the 'message' tool for cross-channel messaging.

## Media Handling

When receiving media content, choose the spawn template by media type:
- **Images only** (photos, screenshots, [å›¾ç‰‡]): Use `template=vision` with `attach_media=true`. Vision is for image analysis/recognition, NOT for audio.
- **Audio/voice only** ([è¯­éŸ³], .mp3/.wav/.ogg): Use `template=voice` with `attach_media=true`. Voice is for speech-to-text transcription, NOT for images.

**CRITICAL**: Never use `voice` template when the user sends images. Never use `vision` template when the user sends only audio. Match template to media type.
**Important**: Always set `attach_media=true` when using spawn with vision or voice templates."""


class ContextBuilder:
    """
    Builds the context (system prompt + messages) for the agent.

    Assembles bootstrap files, memory, skills, and conversation history
    into a coherent prompt for the LLM.

    Supports agent-specific memory isolation when agent_id is provided.
    """

    BOOTSTRAP_FILES = ["AGENTS.md", "SOUL.md", "USER.md", "TOOLS.md"]

    def __init__(self, workspace: Path, agent_id: str | None = None, token_budget: dict[str, int] | None = None):
        self.workspace = workspace
        self.agent_id = agent_id
        self.memory = MemoryStore(workspace, agent_id=agent_id)
        self.skills = SkillsLoader(workspace)
        self.token_budget = {**TOKEN_BUDGET_DEFAULTS, **(token_budget or {})}
    
    def update_token_budget(self, **kwargs: int) -> None:
        """Update token budget settings at runtime."""
        self.token_budget.update(kwargs)
    
    def build_system_prompt(
        self,
        skill_names: list[str] | None = None,
        max_tokens: int | None = None,
        user_message: str | None = None,
        dynamic_skills: bool = True,
    ) -> str:
        """
        Build the system prompt from bootstrap files, memory, and skills.
        
        Args:
            skill_names: Optional list of skills to include.
            max_tokens: Maximum tokens for the system prompt. Uses token_budget["total"] if not specified.
            user_message: Optional user message for dynamic skill matching.
            dynamic_skills: If True, use dynamic skill loading based on user message.
        
        Returns:
            Complete system prompt.
        """
        budget = max_tokens or self.token_budget["total"]
        parts = []
        current_tokens = 0
        
        identity = self._get_identity()
        identity_tokens = estimate_tokens(identity)
        if identity_tokens > self.token_budget["identity"]:
            identity = truncate_to_token_limit(identity, self.token_budget["identity"])
            identity_tokens = estimate_tokens(identity)
        parts.append(identity)
        current_tokens += identity_tokens
        
        remaining = max(0, budget - current_tokens)
        bootstrap_budget = min(
            self.token_budget["bootstrap"],
            remaining - self.token_budget["memory"] - self.token_budget["skills"]
        )
        if bootstrap_budget > 200:
            bootstrap = self._load_bootstrap_files()
            if bootstrap:
                bootstrap_tokens = estimate_tokens(bootstrap)
                if bootstrap_tokens > bootstrap_budget:
                    bootstrap = truncate_to_token_limit(bootstrap, bootstrap_budget)
                parts.append(bootstrap)
                current_tokens += estimate_tokens(bootstrap)
        
        remaining = max(0, budget - current_tokens)
        memory_budget = min(
            self.token_budget["memory"],
            remaining - self.token_budget["skills"]
        )
        if memory_budget > 200:
            memory = self.memory.get_memory_context(max_tokens=memory_budget)
            if memory:
                parts.append(f"# Memory\n\n{memory}")
                current_tokens += estimate_tokens(memory)
        
        always_skills_budget = budget - current_tokens - self.token_budget["skills"]
        always_skills = self.skills.get_always_skills()
        if always_skills and always_skills_budget > 0:
            always_content = self.skills.load_skills_for_context(always_skills)
            if always_content:
                always_tokens = estimate_tokens(always_content)
                if always_tokens > always_skills_budget:
                    always_content = truncate_to_token_limit(always_content, always_skills_budget)
                    always_tokens = estimate_tokens(always_content)
                parts.append(f"# Active Skills\n\n{always_content}")
                current_tokens += always_tokens
        
        skills_budget = min(
            self.token_budget["skills"],
            budget - current_tokens
        )
        if skills_budget > 50:
            if dynamic_skills and user_message:
                skills_summary = self.skills.build_dynamic_summary(user_message)
            else:
                skills_summary = self.skills.build_skills_summary(level=0)
            
            if skills_summary:
                skills_tokens = estimate_tokens(skills_summary)
                if skills_tokens > skills_budget:
                    skills_summary = truncate_to_token_limit(skills_summary, skills_budget)
                parts.append(f"""# Skills

Skills extend your capabilities. To use a skill, read its SKILL.md file with read_file tool.
(âœ“ = available, âœ— = missing dependencies)

{skills_summary}""")
        
        return "\n\n---\n\n".join(parts)
    
    def _get_identity(self) -> str:
        """èŽ·å–ä¸» Agent èº«ä»½åŒºå—ã€‚ä¼˜å…ˆçº§ï¼šDB é…ç½® > IDENTITY.md > å†…ç½®é»˜è®¤ã€‚"""
        from datetime import datetime

        from nanobot.storage import memory_repository
        from nanobot.storage.main_agent_prompt_repository import MainAgentPromptRepository

        now = datetime.now().strftime("%Y-%m-%d %H:%M (%A)")
        workspace_path = str(self.workspace.expanduser().resolve())
        runtime_suffix = f"""

## Current Time
{now}

## Workspace
{workspace_path}
- é•¿æœŸè®°å¿†ä¸Žæ—¥ç¨‹ç¬”è®°ï¼šå­˜å‚¨åœ¨ {workspace_path}/.nanobot/chat.dbï¼ˆSQLiteï¼‰ï¼Œä½¿ç”¨ remember å·¥å…·å†™å…¥
- User skills: {workspace_path}/skills/
- Skill paths: see Skills section below (each entry shows the exact SKILL.md path)
"""
        # 1. ä¼˜å…ˆä»Ž SQLite è¯»å–ç”¨æˆ·å¯è§†åŒ–é…ç½®
        db_path = memory_repository.MemoryRepository.get_workspace_db_path(self.workspace)
        if not db_path.exists():
            db_path = memory_repository.MemoryRepository.get_default_db_path()
        repo = MainAgentPromptRepository(db_path)
        row = repo.get(workspace_path)
        if row and (row.get("identity_content") or "").strip():
            return (row["identity_content"].rstrip() + runtime_suffix)
        # 2. å…¶æ¬¡ä»Ž workspace/IDENTITY.md
        identity_file = self.workspace / "IDENTITY.md"
        if identity_file.exists():
            content = identity_file.read_text(encoding="utf-8").strip()
            if content:
                return content.rstrip() + runtime_suffix
        # 3. å†…ç½®é»˜è®¤
        return DEFAULT_IDENTITY_CONTENT.rstrip() + runtime_suffix
    
    def _load_bootstrap_files(self) -> str:
        """Load all bootstrap files from workspace."""
        parts = []
        
        for filename in self.BOOTSTRAP_FILES:
            file_path = self.workspace / filename
            if file_path.exists():
                content = file_path.read_text(encoding="utf-8")
                parts.append(f"## {filename}\n\n{content}")
        
        return "\n\n".join(parts) if parts else ""
    
    def build_messages(
        self,
        history: list[dict[str, Any]],
        current_message: str,
        skill_names: list[str] | None = None,
        media: list[str] | None = None,
        channel: str | None = None,
        chat_id: str | None = None,
        mirror_attack_level: str | None = None,
        dynamic_skills: bool = True,
    ) -> list[dict[str, Any]]:
        """
        Build the complete message list for an LLM call.

        Args:
            history: Previous conversation messages.
            current_message: The new user message.
            skill_names: Optional skills to include.
            media: Optional list of local file paths for images/media.
            channel: Current channel (telegram, feishu, etc.).
            chat_id: Current chat/user ID.
            mirror_attack_level: For mirror bian sessions, the attack level (light/medium/heavy).
            dynamic_skills: If True, use dynamic skill loading based on user message.

        Returns:
            List of messages including system prompt.
        """
        messages = []

        system_prompt = self.build_system_prompt(
            skill_names=skill_names,
            user_message=current_message,
            dynamic_skills=dynamic_skills,
        )
        if channel and chat_id:
            system_prompt += f"\n\n## Current Session\nChannel: {channel}\nChat ID: {chat_id}"
        CHANNEL_MIRROR = "mirror"
        ATTACK_DESCRIPTIONS = {
            "light": "å‹å–„è¿½é—®ï¼Œç‚¹åˆ°ä¸ºæ­¢ï¼Œä¸æ–½åŠ åŽ‹åŠ›",
            "medium": "ä¸¾ä¾‹åä¾‹ï¼Œé€‚åº¦æ–½åŽ‹ï¼Œæ¸©å’ŒæŒ‘æˆ˜ç”¨æˆ·è§‚ç‚¹",
            "heavy": "ç›´æŒ‡åŒæ ‡ä¸ŽçŸ›ç›¾ï¼ŒçŠ€åˆ©è¿½é—®ï¼Œå¼ºåŽ‹åŠ›æµ‹è¯•",
        }
        if mirror_attack_level and channel == CHANNEL_MIRROR:
            desc = ATTACK_DESCRIPTIONS.get(
                mirror_attack_level.lower() if isinstance(mirror_attack_level, str) else "",
                ATTACK_DESCRIPTIONS["medium"],
            )
            system_prompt += (
                f"\n\n## é•œå®¤-è¾©è®ºæ¨¡å¼\næœ¬è½®æ”»å‡»å¼ºåº¦: {mirror_attack_level}\n"
                f"è¯·ä¸¥æ ¼æŒ‰æ­¤é£Žæ ¼è¿½é—®: {desc}"
            )
        messages.append({"role": "system", "content": system_prompt})

        messages.extend(history)

        user_content = self._build_user_content(current_message, media)
        messages.append({"role": "user", "content": user_content})

        return messages

    def _build_user_content(self, text: str, media: list[str] | None) -> str | list[dict[str, Any]]:
        """Build user message content with optional base64-encoded images."""
        if not media:
            return text
        
        images = []
        for path in media:
            p = Path(path)
            mime, _ = mimetypes.guess_type(path)
            if not p.is_file() or not mime or not mime.startswith("image/"):
                continue
            b64 = base64.b64encode(p.read_bytes()).decode()
            images.append({"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}})
        
        if not images:
            return text
        return images + [{"type": "text", "text": text}]
    
    def add_tool_result(
        self,
        messages: list[dict[str, Any]],
        tool_call_id: str,
        tool_name: str,
        result: str
    ) -> list[dict[str, Any]]:
        """
        Add a tool result to the message list.
        
        Args:
            messages: Current message list.
            tool_call_id: ID of the tool call.
            tool_name: Name of the tool.
            result: Tool execution result.
        
        Returns:
            Updated message list.
        """
        messages.append({
            "role": "tool",
            "tool_call_id": tool_call_id,
            "name": tool_name,
            "content": result
        })
        return messages
    
    def add_assistant_message(
        self,
        messages: list[dict[str, Any]],
        content: str | None,
        tool_calls: list[dict[str, Any]] | None = None
    ) -> list[dict[str, Any]]:
        """
        Add an assistant message to the message list.
        
        Args:
            messages: Current message list.
            content: Message content.
            tool_calls: Optional tool calls.
        
        Returns:
            Updated message list.
        """
        msg: dict[str, Any] = {"role": "assistant", "content": content or ""}
        
        if tool_calls:
            msg["tool_calls"] = tool_calls
        
        messages.append(msg)
        return messages
